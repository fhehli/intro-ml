{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "from functools import partial\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import transforms, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torch.linalg import norm\n",
    "from torch.optim import Adam, SGD\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "BASE = \"../\"  # where the data is located\n",
    "IMG_DIR = BASE + \"food\"  # where you unzipped food.zip\n",
    "TRAIN_PATH = BASE + \"train_triplets.txt\"\n",
    "TEST_PATH = BASE + \"test_triplets.txt\"\n",
    "\n",
    "\n",
    "def get_split(val_ratio):\n",
    "    triplets = np.loadtxt(TRAIN_PATH, delimiter=\" \").astype(int)\n",
    "    train_triplets, val_triplets = train_test_split(\n",
    "        triplets, test_size=val_ratio, random_state=489, shuffle=True\n",
    "    )\n",
    "    return train_triplets, val_triplets\n",
    "\n",
    "\n",
    "def get_features(name):\n",
    "    pkl_path = f\"{name}_features.pkl\"\n",
    "\n",
    "    if name == \"ResNet18\":\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "    elif name == \"ResNet34\":\n",
    "        backbone = models.resnet34(pretrained=True)\n",
    "    elif name == \"ResNet50\":\n",
    "        backbone = models.resnet50(pretrained=True)\n",
    "    elif name == \"ResNet101\":\n",
    "        backbone = models.resnet101(pretrained=True)\n",
    "    elif name == \"ResNet152\":\n",
    "        backbone = models.resnet152(pretrained=True)\n",
    "    elif name == \"EfficientNetb0\":\n",
    "        backbone = models.efficientnet_b0(pretrained=True)\n",
    "    elif name == \"EfficientNetb1\":\n",
    "        backbone = models.efficientnet_b1(pretrained=True)\n",
    "    elif name == \"EfficientNetb2\":\n",
    "        backbone = models.efficientnet_b2(pretrained=True)\n",
    "    elif name == \"EfficientNetb3\":\n",
    "        backbone = models.efficientnet_b3(pretrained=True)\n",
    "    elif name == \"EfficientNetb4\":\n",
    "        backbone = models.efficientnet_b4(pretrained=True)\n",
    "    elif name == \"EfficientNetb5\":\n",
    "        backbone = models.efficientnet_b5(pretrained=True)\n",
    "    elif name == \"EfficientNetb6\":\n",
    "        backbone = models.efficientnet_b6(pretrained=True)\n",
    "    elif name == \"EfficientNetb7\":\n",
    "        backbone = models.efficientnet_b7(pretrained=True)\n",
    "    elif name == \"ViT_b_16\":\n",
    "        backbone = models.vit_b_16(pretrained=True)\n",
    "    elif name == \"ViT_b_32\":\n",
    "        backbone = models.vit_b_32(pretrained=True)\n",
    "    elif name == \"ViT_l_16\":\n",
    "        backbone = models.vit_l_16(pretrained=True)\n",
    "    elif name == \"ViT_l_32\":\n",
    "        backbone = models.vit_l_32(pretrained=True)\n",
    "    else:\n",
    "        sys.exit(\"Error: This model is not implemented.\")\n",
    "\n",
    "    if name.startswith(\"ResNet\"):\n",
    "        features_dim = backbone.fc.in_features\n",
    "    elif name.startswith(\"EfficientNet\"):\n",
    "        features_dim = backbone.classifier[1].in_features\n",
    "    elif name.startswith(\"ViT\"):\n",
    "        features_dim = backbone.heads[0].in_features\n",
    "\n",
    "    if os.path.exists(pkl_path):\n",
    "        # fetch precopmuted features from earlier run\n",
    "        with open(pkl_path, \"rb\") as f:\n",
    "            features = pickle.load(f)\n",
    "    else:\n",
    "        # compute features\n",
    "        if name.startswith(\"ResNet\") or name.startswith(\"EfficientNet\"):\n",
    "            feature_map = nn.Sequential(*list(backbone.children())[:-1])\n",
    "            tfms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((242, 354)),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                ]\n",
    "            )  # preprocessing function\n",
    "        elif name.startswith(\"ViT\"):\n",
    "            feature_map = nn.Sequential(*list(backbone.children())[:-1])[1]\n",
    "            tfms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                ]\n",
    "            )  # preprocessing function\n",
    "\n",
    "        feature_map.cuda().eval()\n",
    "\n",
    "        n_imgs = 10_000\n",
    "        features = torch.empty((n_imgs, features_dim))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for i in tqdm(range(n_imgs)):\n",
    "                path = os.path.join(IMG_DIR, f\"{str(i).rjust(5, '0')}.jpg\")\n",
    "                img = tfms(Image.open(path)).unsqueeze(0).cuda()\n",
    "                if name.startswith(\"ResNet\") or name.startswith(\"EfficientNet\"):\n",
    "                    phi = feature_map(img)  # forward pass\n",
    "                elif name.startswith(\"ViT\"):\n",
    "                    x = backbone._process_input(img)\n",
    "                    batch_class_token = backbone.class_token.expand(x.shape[0], -1, -1)\n",
    "                    x = torch.cat([batch_class_token, x], dim=1)\n",
    "                    phi = feature_map(x)[:, 0]\n",
    "                features[i] = phi.squeeze()\n",
    "\n",
    "        features = features.cpu().float()\n",
    "\n",
    "        # save features\n",
    "        with open(pkl_path, \"wb\") as f:\n",
    "            pickle.dump(features, f)\n",
    "\n",
    "    return features, features_dim\n",
    "\n",
    "\n",
    "class TripletsDataset(Dataset):\n",
    "    def __init__(self, triplets, features):\n",
    "        self.triplets = triplets\n",
    "        self.features = features\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triplets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        triplet = self.triplets[idx]\n",
    "        a, b, c = self.features[triplet]\n",
    "        return a, b, c\n",
    "\n",
    "\n",
    "# this defines our network.\n",
    "# we use a pytorch lightning LightningModule instead of a nn.Module\n",
    "# for its convenient features. Hence why we implement many of the\n",
    "# methods below, they are reserved by lightning and used by the\n",
    "# trainer\n",
    "class SimilarityNet(pl.LightningModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        features_dim,\n",
    "        margin=5.0,\n",
    "        embedding_dim=1024,\n",
    "        lr=1e-3,\n",
    "        momentum=0.9,\n",
    "        nesterov=True,\n",
    "        weight_decay=1e-3,\n",
    "        batch_size=8,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        self.momentum = momentum\n",
    "        self.nesterov = nesterov\n",
    "        self.weight_decay = weight_decay\n",
    "\n",
    "        self.embedding = nn.Linear(features_dim, embedding_dim)\n",
    "\n",
    "        self.loss = nn.TripletMarginLoss(margin=margin)\n",
    "        self.val_loss = partial(F.triplet_margin_loss, margin=0)\n",
    "\n",
    "    def forward(self, a, b, c):\n",
    "        embedded_a = self.embedding(a)\n",
    "        embedded_b = self.embedding(b)\n",
    "        embedded_c = self.embedding(c)\n",
    "\n",
    "        return embedded_a, embedded_b, embedded_c\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        a, b, c = batch\n",
    "        embedded_a, embedded_b, embedded_c = self(a, b, c)\n",
    "        loss = self.loss(embedded_a, embedded_b, embedded_c)\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, idx):\n",
    "        a, b, c = batch\n",
    "        embedded_a, embedded_b, embedded_c = self(a, b, c)\n",
    "        loss = self.val_loss(embedded_a, embedded_b, embedded_c)\n",
    "        self.log(\"val_loss\", loss)\n",
    "\n",
    "        d_ab = norm(embedded_a - embedded_b, axis=-1).squeeze()\n",
    "        d_ac = norm(embedded_a - embedded_c, axis=-1).squeeze()\n",
    "        acc = (d_ab <= d_ac).float().mean()\n",
    "        self.log(\"val_acc\", acc)\n",
    "\n",
    "        return {\"val_loss\": loss, \"val_acc\": acc}\n",
    "\n",
    "    def predict_step(self, batch, idx):\n",
    "        a, b, c = batch\n",
    "        embedded_a, embedded_b, embedded_c = self(a, b, c)\n",
    "        d_ab = norm(embedded_a - embedded_b, axis=-1).squeeze()\n",
    "        d_ac = norm(embedded_a - embedded_c, axis=-1).squeeze()\n",
    "        pred = (d_ab <= d_ac).int()\n",
    "        return pred\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return SGD(\n",
    "            self.parameters(),\n",
    "            lr=self.learning_rate,\n",
    "            momentum=self.momentum,\n",
    "            nesterov=self.nesterov,\n",
    "            weight_decay=self.weight_decay,\n",
    "        )\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x[\"val_acc\"] for x in outputs]).mean()\n",
    "        self.log(\"val_loss\", avg_loss)\n",
    "        self.log(\"val_acc\", avg_acc)\n",
    "\n",
    "\n",
    "# first we compute the embedded images with a pretrained network\n",
    "BACKBONE = \"EfficientNetb0\"  # choose one of ResNet{18,34,50,101,152}, EfficientNetb{0,1,2,3,4,5,6,7}, ViT_{b_16,b_32,l_16,l_32}\n",
    "features, features_dim = get_features(BACKBONE)\n",
    "\n",
    "# hyperparameters\n",
    "EMBEDDING_DIM = 1024\n",
    "LEARNING_RATE = 1e-3\n",
    "MOMENTUM = 0.9\n",
    "NESTEROV = True\n",
    "WEIGHT_DECAY = 1e-3\n",
    "MARGIN = 5.0\n",
    "VAL_RATIO = 0.1\n",
    "BATCH_SIZE = 4096\n",
    "NUM_WORKERS = 32\n",
    "\n",
    "train_triplets, val_triplets = get_split(VAL_RATIO)\n",
    "train_dataset = TripletsDataset(train_triplets, features)\n",
    "val_dataset = TripletsDataset(val_triplets, features)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    ")\n",
    "\n",
    "bar = TQDMProgressBar(refresh_rate=1)\n",
    "early_stop = EarlyStopping(\n",
    "    monitor=\"val_acc\", mode=\"max\", min_delta=0.002, patience=10, verbose=True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    # fast_dev_run=True, # uncomment to debug\n",
    "    accelerator=\"gpu\",\n",
    "    devices=torch.cuda.device_count(),\n",
    "    auto_select_gpus=True,\n",
    "    min_epochs=1,\n",
    "    max_epochs=1000,\n",
    "    callbacks=[bar, early_stop],\n",
    "    auto_lr_find=True,\n",
    "    auto_scale_batch_size=False,\n",
    ")\n",
    "\n",
    "model = SimilarityNet(\n",
    "    features_dim=features_dim,\n",
    "    margin=MARGIN,\n",
    "    lr=LEARNING_RATE,\n",
    "    momentum=MOMENTUM,\n",
    "    nesterov=NESTEROV,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "# trainer.tune(model)\n",
    "trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n",
    "\n",
    "# predict\n",
    "test_triplets = np.loadtxt(TEST_PATH, delimiter=\" \").astype(int)\n",
    "test_dataset = TripletsDataset(test_triplets, features)\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    persistent_workers=True,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "predictions = trainer.predict(model, test_loader)\n",
    "predictions = torch.cat(predictions).tolist()\n",
    "\n",
    "df_pred = pd.DataFrame(predictions)\n",
    "sub_path = f\"{BACKBONE}.txt\"\n",
    "df_pred.to_csv(f\"../predictions/{sub_path}\", index=False, header=None)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e751ec60a2bd0b39245754ddff26773aef4db6007d14158e17e04fcfd719773a"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
